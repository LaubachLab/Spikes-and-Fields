{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save your workspace in Python\n",
    "\n",
    "A major issue for me coming to Python from Matlab was how to save my workspaces. This is especially crucial when finalizing results in support of a manuscript. It is painful to have reviewers to ask for other statistics or new analyses and have to run everything over again to address such issues. Also, some analyses take a _long_ time to run. So, how the heck does one save workspace variables into a file in Python? It turns out to be not that difficult. Several established libraries exist for this purpose. One of these libraries, [dill](https://pypi.python.org/pypi/dill), is very good for short-term saves. Others are better for long-term data storage and for sharing with others who might still be dependent on Matlab or who use R.\n",
    "\n",
    "The code below brings in five options for saving your workspace.\n",
    "\n",
    "By the way, this code was written on PCs running [Linux Mint](https://www.linuxmint.com/), an Ubuntu variant, and the Python installation was based on Continuum Analytics [Anaconda](https://www.continuum.io/anaconda-overview) Python distro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[dill](https://pypi.python.org/pypi/dill) is an extension of Python pickle module that enables saving (serializing) most of the common Python datatypes. It depends on the version of Python and libraries that are installed on the computer that creates the dilled workspace. For me, it is the go-to library for when I am working on analysis on my office PC and need to head out and carry on using my notebook. However, given its limitation (dependence on version of Python and libraries), it does not seem like a good idea for long-term data storage.\n",
    "\n",
    "numpy has a nice function called [savez](https://docs.scipy.org/doc/numpy/reference/generated/numpy.savez.html#numpy.savez) that saves several arrays into a single file in an uncompressed or compressed format. It is fast to use, but depends on Python. However, recently a library for R called [RcppCNPy](https://cran.rstudio.com/web/packages/RcppCNPy/index.html) was written that makes it easy to load and save data in this format.\n",
    "\n",
    "scipy includes functions for reading and writing Matlab version 4 and 5 files, [savemat](https://docs.scipy.org/doc/scipy-0.18.1/reference/generated/scipy.io.savemat.html) and [loadmat]https://docs.scipy.org/doc/scipy-0.18.1/reference/generated/scipy.io.loadmat.html. These are very useful especially if you are using both Python and Matlab or have collaborators stuck on Matlab.\n",
    "\n",
    "Perhaps the best long-term storage format is [hdf](https://www.hdfgroup.org/). This format is used for the most recent versions of Matlab and can be directly read into GNU-Octave. Well-established libraries exist for working with hdf files in R and Julia. The HDF Group supplies a [viewer](https://support.hdfgroup.org/products/java/hdfview/index.html) for hdf files that makes it easy to check on the contents of a file without reading the file into Python. I have found that two Python libraries, [h5py](http://www.h5py.org/) and [hdf5storage](https://github.com/frejanordsiek/hdf5storage), useful for working with hdf files in Python. h5py is fast and easy to use. hdf5storage is slower but produces compressed saves by default. \n",
    "\n",
    "This notebook shows how to use these libraries for saving your workspace in Python. The data set is part of the demo data file provided with [NeuronExplorer](http://www.neuroexplorer.com/), written by my grad school lab colleague Alex Kirillov. NeuronExplorer is an excellent tool for working with neurophysiological datafiles. My lab depends on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to import the relevant libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import dill\n",
    "import numpy as np\n",
    "from scipy.io import loadmat, savemat\n",
    "import h5py\n",
    "import hdf5storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Switch folders and load the neuronal data, which were parsed out of a nex file using old Matlab code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mark/Desktop/Spikes-and-Fields/NEx-demo\n"
     ]
    }
   ],
   "source": [
    "%cd ~/Desktop/Spikes-and-Fields/NEx-demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NEx_demo = loadmat('SpikesAndFields.mat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loadmat puts the variables from the Matlab/Octave workspace into a dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Event05', '__globals__', 'Neuron06d', 'fn', 'ans', 'ts', 'Neuron04a', '__header__', 'Neuron06b', 'Event06', 'Neuron05b', 'Neuron05c', 'Neuron07a', 'adfreq', 'AD01', '__version__', 'Event04', 'FILE'])\n"
     ]
    }
   ],
   "source": [
    "Keys = NEx_demo.keys()\n",
    "print(Keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My work style is to put each neuron, lfp, or behavioral event into its own variable in the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Neuron04a = NEx_demo['Neuron04a']\n",
    "Neuron05b = NEx_demo['Neuron05b']\n",
    "Neuron05c = NEx_demo['Neuron05c']\n",
    "Neuron06b = NEx_demo['Neuron06b']\n",
    "Neuron06d = NEx_demo['Neuron06d']\n",
    "Neuron07a = NEx_demo['Neuron07a']\n",
    "Event04 = NEx_demo['Event04']\n",
    "Event05 = NEx_demo['Event05']\n",
    "Event06 = NEx_demo['Event06']\n",
    "ADmat = NEx_demo['AD01']  # LFP data\n",
    "adfreq = NEx_demo['adfreq'] # sampling frequency\n",
    "ts = NEx_demo['ts'] # ts is the temporal offset between spikes/events and fields in the Plexon recording file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%xdel NEx_demo\n",
    "%xdel Keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the arrays in the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable    Type       Data/Info\n",
      "--------------------------------\n",
      "ADmat       ndarray    1x610207: 610207 elems, type `float64`, 4881656 bytes (4.655509948730469 Mb)\n",
      "Event04     ndarray    1x862: 862 elems, type `float64`, 6896 bytes\n",
      "Event05     ndarray    1x752: 752 elems, type `float64`, 6016 bytes\n",
      "Event06     ndarray    1x385: 385 elems, type `float64`, 3080 bytes\n",
      "Neuron04a   ndarray    1x18882: 18882 elems, type `float64`, 151056 bytes (147.515625 kb)\n",
      "Neuron05b   ndarray    1x13514: 13514 elems, type `float64`, 108112 bytes (105.578125 kb)\n",
      "Neuron05c   ndarray    1x3053: 3053 elems, type `float64`, 24424 bytes\n",
      "Neuron06b   ndarray    1x2357: 2357 elems, type `float64`, 18856 bytes\n",
      "Neuron06d   ndarray    1x3807: 3807 elems, type `float64`, 30456 bytes\n",
      "Neuron07a   ndarray    1x3824: 3824 elems, type `float64`, 30592 bytes\n",
      "adfreq      ndarray    1x1: 1 elems, type `float64`, 8 bytes\n",
      "ts          ndarray    1x1: 1 elems, type `float64`, 8 bytes\n"
     ]
    }
   ],
   "source": [
    "%whos ndarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Switch to a temporary directory to evaluate saving using the various Python tools. \n",
    "\n",
    "(I use Dropbox and SpiderOak for backups, but my temp folder is not backed up. I hate wasting bandwidth.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mark/temp\n"
     ]
    }
   ],
   "source": [
    "%cd ~/temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dill\n",
    "\n",
    "dill is *REALLY* useful for saving the entire workspace, e.g. when shutting down notebook, heading home, and picking up work after dinner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 12 ms, total: 12 ms\n",
      "Wall time: 12 ms\n"
     ]
    }
   ],
   "source": [
    "%time dill.dump_session('test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5144 -rw-r--r-- 1 mark mark 5264642 Jun 29 15:56 test.pkl\r\n"
     ]
    }
   ],
   "source": [
    "ls -lstr test.pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* dill is an optimal way to save intermediate files or your workspace\n",
    "* e.g. working in coffee shop and want to save progress while coding; save end-of-day coding and pick up on notebook at home after dinner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactive namespace is empty.\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "%who"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 8 ms, total: 8 ms\n",
      "Wall time: 4.15 ms\n",
      "Variable      Type        Data/Info\n",
      "-----------------------------------\n",
      "ADmat         ndarray     1x610207: 610207 elems, type `float64`, 4881656 bytes (4.655509948730469 Mb)\n",
      "Event04       ndarray     1x862: 862 elems, type `float64`, 6896 bytes\n",
      "Event05       ndarray     1x752: 752 elems, type `float64`, 6016 bytes\n",
      "Event06       ndarray     1x385: 385 elems, type `float64`, 3080 bytes\n",
      "In            list        n=10\n",
      "Neuron04a     ndarray     1x18882: 18882 elems, type `float64`, 151056 bytes (147.515625 kb)\n",
      "Neuron05b     ndarray     1x13514: 13514 elems, type `float64`, 108112 bytes (105.578125 kb)\n",
      "Neuron05c     ndarray     1x3053: 3053 elems, type `float64`, 24424 bytes\n",
      "Neuron06b     ndarray     1x2357: 2357 elems, type `float64`, 18856 bytes\n",
      "Neuron06d     ndarray     1x3807: 3807 elems, type `float64`, 30456 bytes\n",
      "Neuron07a     ndarray     1x3824: 3824 elems, type `float64`, 30592 bytes\n",
      "Out           dict        n=0\n",
      "adfreq        ndarray     1x1: 1 elems, type `float64`, 8 bytes\n",
      "dill          module      <module 'dill' from '/hom<...>ckages/dill/__init__.py'>\n",
      "h5py          module      <module 'h5py' from '/hom<...>ckages/h5py/__init__.py'>\n",
      "hdf5storage   module      <module 'hdf5storage' fro<...>hdf5storage/__init__.py'>\n",
      "loadmat       function    <function loadmat at 0x7f7ad0077158>\n",
      "np            module      <module 'numpy' from '/ho<...>kages/numpy/__init__.py'>\n",
      "savemat       function    <function savemat at 0x7f7ad00771e0>\n",
      "ts            ndarray     1x1: 1 elems, type `float64`, 8 bytes\n"
     ]
    }
   ],
   "source": [
    "import dill\n",
    "%time dill.load_session('test.pkl')\n",
    "%whos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compare hdf5, hdf5storage, np's save, and scipy's savemat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike numpy's savez and scipy's savemat, hdf5 needs to know the datatypes that are to be saved. For this example, ADmat, W, and icasig are ndarrays and adfreq and ts are floats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>HDF5</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 120 ms, sys: 4 ms, total: 124 ms\n",
      "Wall time: 123 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with h5py.File('test.h5', 'w') as hf:\n",
    "    hf.create_dataset('ADmat', data=ADmat, compression=\"gzip\", shuffle=True)\n",
    "    hf.create_dataset('adfreq', data=adfreq, compression=\"gzip\", shuffle=True)\n",
    "    hf.create_dataset('ts', data=ts, compression=\"gzip\", shuffle=True)\n",
    "    hf.create_dataset('Event04', data=Event04, compression=\"gzip\", shuffle=True)\n",
    "    hf.create_dataset('Neuron04a', data=Neuron04a, compression=\"gzip\", shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1588 -rw-r--r-- 1 mark mark 1626060 Jun 29 15:59 test.h5\r\n"
     ]
    }
   ],
   "source": [
    "ls -lstr test.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**all files verified using hdf viewer; file loads directly into Octave and Matlab**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>hdf5storage</b> -- default options are much slower than direct calls to h5py; however, the file is saved more efficiently, and this effect is more apparent with more LFP channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dict is used to set up variables for hdf5storate.writes\n",
    "vars = {'ADmat':ADmat, 'adfreq':adfreq, 'ts':ts, 'Event04':Event04, 'Neuron04a':Neuron04a}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 404 ms, sys: 12 ms, total: 416 ms\n",
      "Wall time: 415 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "hdf5storage.writes(vars, filename='test_hdf5storage.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1544 -rw-r--r-- 1 mark mark 1578914 Jun 29 16:03 test_hdf5storage.h5\r\n"
     ]
    }
   ],
   "source": [
    "ls -lstr test_hdf5storage.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* hdf5storage is easy to use, handles compression without effort, and is based on a stable format (H5) that can also be read into Matlab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>np.savez</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20 ms, sys: 28 ms, total: 48 ms\n",
      "Wall time: 61.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "np.savez('test', 'ADmat':ADmat, 'adfreq':adfreq, 'ts':ts, 'Event04':Event04, 'Neuron04a':Neuron04a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4924 -rw-r--r-- 1 mark mark 5040524 Jun 29 16:05 test.npz\r\n"
     ]
    }
   ],
   "source": [
    "ls -lstr test.npz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this format seems to be stable and standard; a library exists for reading it into R (RcppCNPy: https://cran.r-project.org/web/packages/RcppCNPy/vignettes/RcppCNPy-intro.pdf); this would be useful for saving intermediate files between R and Python, and could be used as a long-term option, for Python only; however, the compressed options are no better than 8% (from my testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>savemat</b>  (v5 matlab, from scipy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 ms, sys: 4 ms, total: 8 ms\n",
      "Wall time: 6.55 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "savemat('test.mat', vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4924 -rw-r--r-- 1 mark mark 5040072 Jun 29 16:08 test.mat\r\n"
     ]
    }
   ],
   "source": [
    "ls -lstr test.mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is a **fast** way to save data in a format that is easily read into and out of Matlab/Octave\n",
    "\n",
    "this format is much faster than H5, but does not offer compression and requires a slow (and complex) library to be read into R (R.matlab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**clean up**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 18124\r\n",
      "5144 -rw-r--r-- 1 mark mark 5264642 Jun 29 15:56 test.pkl\r\n",
      "1588 -rw-r--r-- 1 mark mark 1626060 Jun 29 15:59 test.h5\r\n",
      "1544 -rw-r--r-- 1 mark mark 1578914 Jun 29 16:03 test_hdf5storage.h5\r\n",
      "4924 -rw-r--r-- 1 mark mark 5040524 Jun 29 16:05 test.npz\r\n",
      "4924 -rw-r--r-- 1 mark mark 5040072 Jun 29 16:08 test.mat\r\n"
     ]
    }
   ],
   "source": [
    "ls -lstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rm test*.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feather and blospack are other options; blospack is very fast compression, but the Github page cautions about long term stability; same is true for feather; it is very fast but again the Github page cautions on stability and the Python implementation currently does not work with row-to-column conversions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
